[tool.poetry]
name = "biomedical-llm"
version = "0.1.0"
description = "Biomedical LLM Service environment"
authors = ["Rick Vu Truong <ricktruong@Ricks-MacBook-Pro.local>"]
readme = "README.md"
package-mode = false

[tool.poetry.dependencies]
python = "^3.8"
fastapi = "^0.116.0"
pydantic = "^2.0.0"
pydantic-settings = "^2.0.0"
structlog = "^24.1.0"
python-dotenv = "<1.1.0"
uvicorn = "<0.24.0"
common = {path = "../common"}

# OpenAI and HTTP client dependencies (required for LLM service)
openai = "^1.0.0"
httpx = "^0.27.0"

[tool.poetry.group.ml]
optional = true

[tool.poetry.group.ml.dependencies]
# PyTorch for x86_64 systems (optional - only for future local models)
torch = "^2.0.0"
monai = "<1.0.0"
transformers = ">=4.20.0,<4.30.0"
sacremoses = "^0.1.1"



[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
