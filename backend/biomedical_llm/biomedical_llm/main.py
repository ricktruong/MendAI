from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import os
import logging

app = FastAPI()
logger = logging.getLogger(__name__)

# Allow all origins for now (adjust in production)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Request/Response Models
class ChatMessage(BaseModel):
    role: str  # "user" or "assistant"
    content: str

class ChatRequest(BaseModel):
    messages: List[ChatMessage]
    patient_id: Optional[str] = None
    model: Optional[str] = "biomedlm"  # biomedlm, biomistral, openbiollm

class ChatResponse(BaseModel):
    response: str
    model_used: str

@app.get("/")
def read_root():
    return {"message": "Biomedical LLM Service is running!"}

@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    Chat endpoint for biomedical LLM inference

    Supports multiple biomedical models:
    - biomedlm: Stanford BioMedLM
    - biomistral: BioMistral via Ollama (requires Ollama installed)
    - openbiollm: OpenBioLLM via Ollama (requires Ollama installed)
    """
    try:
        logger.info(f"Received chat request with {len(request.messages)} messages")

        # Extract the latest user message
        user_messages = [msg for msg in request.messages if msg.role == "user"]
        if not user_messages:
            raise HTTPException(status_code=400, detail="No user messages found")

        latest_message = user_messages[-1].content

        # For now, we'll use a mock response
        # TODO: Implement actual model inference based on request.model

        response_text = f"""Based on the clinical information provided, here are my findings:

**Clinical Assessment:**
The patient's presentation suggests a complex medical condition that requires careful evaluation. Key considerations include:

1. **Primary Concerns**: The symptoms and imaging findings indicate the need for thorough diagnostic workup
2. **Risk Stratification**: Patient factors should be assessed for optimal treatment planning
3. **Recommended Actions**:
   - Complete diagnostic imaging series
   - Laboratory workup including relevant biomarkers
   - Specialist consultation as indicated

**Differential Diagnosis:**
Based on available information, consider:
- Primary etiology related to presenting symptoms
- Secondary complications or comorbidities
- Alternative diagnoses that fit the clinical picture

**Follow-up Plan:**
Close monitoring and reassessment recommended within appropriate timeframe based on clinical urgency.

*Note: This analysis is generated by an AI system and should be reviewed by qualified medical professionals. Not intended to replace clinical judgment.*"""

        return ChatResponse(
            response=response_text,
            model_used=request.model or "biomedlm-mock"
        )

    except Exception as e:
        logger.error(f"Error in chat endpoint: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Chat processing failed: {str(e)}")

@app.get("/models")
def list_models():
    """List available biomedical LLM models"""
    return {
        "available_models": [
            {
                "id": "biomedlm",
                "name": "Stanford BioMedLM",
                "description": "Stanford's biomedical language model",
                "status": "mock"
            },
            {
                "id": "biomistral",
                "name": "BioMistral",
                "description": "Mistral-based biomedical model via Ollama",
                "status": "requires_ollama"
            },
            {
                "id": "openbiollm",
                "name": "OpenBioLLM",
                "description": "LLaMA3-based biomedical model via Ollama",
                "status": "requires_ollama"
            }
        ]
    } 